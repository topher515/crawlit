curl -X POST -d@- http://localhost:50000/ << EOF
http://www.docker.com/
http://www.cnn.com/
http://www.4chan.com/
EOF


### Questions

- Assume list of urls is relatively short

- Only follow "a href=" urls

- Is status unique forever?
- Assume: Statuses should be unique across all connected instances of crawlit 


- What about privacy of results/statuses etc?
- Assume javascript enabled web crawling not important


### Using Crawlit 

# Build my container
docker build -t topher/crawlit:latest .

# Run containers
docker run --name=shivering_wombat redis

# First container
docker run --link=shivering_wombat:redis -p 0.0.0.0:49155:80 -t -i topher/crawlit:latest bash

# Successive containers
docker run --link=shivering_wombat:redis -P -t -i topher/crawlit:latest